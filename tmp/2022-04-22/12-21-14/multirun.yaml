hydra:
  run:
    dir: ${output_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${output_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  launcher:
    submitit_folder: ${hydra.sweep.dir}/.submitit/%j
    timeout_min: 720
    cpus_per_task: 2
    gpus_per_node: null
    tasks_per_node: 1
    mem_gb: null
    nodes: 1
    name: ${hydra.job.name}
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    partition: cpu_short
    qos: null
    comment: null
    constraint: null
    exclude: null
    gres: null
    cpus_per_gpu: null
    gpus_per_task: null
    mem_per_gpu: null
    mem_per_cpu: null
    signal_delay_s: 120
    max_num_timeout: 0
    additional_parameters: {}
    array_parallelism: 256
    setup:
    - unset WANDB_DIR
    - unset WANDB_IGNORE_GLOBS
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    max_batch_size: null
  help:
    app_name: ${hydra.job.name}
    header: '${hydra.help.app_name} is powered by Hydra.

      '
    footer: 'Powered by Hydra (https://hydra.cc)

      Use --hydra-help to view Hydra specific help

      '
    template: '${hydra.help.header}

      == Configuration groups ==

      Compose your configuration from those groups (group=option)


      $APP_CONFIG_GROUPS


      == Config ==

      Override anything in the config (foo.bar=value)


      $CONFIG


      ${hydra.help.footer}

      '
  hydra_help:
    template: 'Hydra (${hydra.runtime.version})

      See https://hydra.cc for more info.


      == Flags ==

      $FLAGS_HELP


      == Configuration groups ==

      Compose your configuration from those groups (For example, append hydra/job_logging=disabled
      to command line)


      $HYDRA_CONFIG_GROUPS


      Use ''--cfg hydra'' to Show the Hydra config.

      '
    hydra_help: ???
  hydra_logging:
    version: 1
    formatters:
      colorlog:
        (): colorlog.ColoredFormatter
        format: '[%(cyan)s%(asctime)s%(reset)s][%(purple)sHYDRA%(reset)s] %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: colorlog
        stream: ext://sys.stdout
    root:
      level: INFO
      handlers:
      - console
    disable_existing_loggers: false
  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
      colorlog:
        (): colorlog.ColoredFormatter
        format: '[%(cyan)s%(asctime)s%(reset)s][%(blue)s%(name)s%(reset)s][%(log_color)s%(levelname)s%(reset)s]
          - %(message)s'
        log_colors:
          DEBUG: purple
          INFO: green
          WARNING: yellow
          ERROR: red
          CRITICAL: red
    handlers:
      console:
        class: logging.StreamHandler
        formatter: colorlog
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${hydra.job.name}.log
    root:
      level: INFO
      handlers:
      - console
      - file
    disable_existing_loggers: false
  env: {}
  searchpath: []
  callbacks: {}
  output_subdir: .hydra
  overrides:
    hydra: []
    task:
    - +experiment=sequential_test
  job:
    name: main
    override_dirname: +experiment=sequential_test
    id: ???
    num: ???
    config_name: base
    env_set: {}
    env_copy: []
    config:
      override_dirname:
        kv_sep: '='
        item_sep: ','
        exclude_keys: []
  runtime:
    version: 1.1.1
    cwd: /home/mohan/git/current_projects/gravitas/AlgoSelectionMF
    config_sources:
    - path: hydra.conf
      schema: pkg
      provider: hydra
    - path: /home/mohan/git/current_projects/gravitas/AlgoSelectionMF/mf_gravitas/config
      schema: file
      provider: main
    - path: hydra_plugins.hydra_colorlog.conf
      schema: pkg
      provider: hydra-colorlog
    - path: ''
      schema: structured
      provider: schema
    choices:
      experiment: sequential_test
      training: sequential
      evaluation: optimal_rankings
      model: autoencoder
      dataset: lcbench
      dataset_raw: lcbench
      hydra/env: default
      hydra/callbacks: null
      hydra/job_logging: colorlog
      hydra/hydra_logging: colorlog
      hydra/hydra_help: default
      hydra/help: default
      hydra/sweeper: basic
      hydra/launcher: submitit_slurm
      hydra/output: default
  verbose: false
dataset_raw:
  dataset_name: LCBench
  dir_data: ../../../data/
  extract: data_2k
  enable: false
  re_download: false
  reload_from_downloads: false
  selection:
    metric: final_test_cross_entropy
    algo:
      _target_: mf_gravitas.data.ensemble.topk.ensemble
      k: 3
  learning_curves:
    metrics:
    - Train/loss
    - Train/lr
    - Train/test_balanced_accuracy
    - Train/test_cross_entropy
    - Train/test_result
    - Train/train_accuracy
    - Train/train_balanced_accuracy
    - Train/train_cross_entropy
    - Train/val_accuracy
    - Train/val_balanced_accuracy
    - Train/val_cross_entropy
    - epoch
    - time
dataset:
  name: LCBench
  preprocessed_path: ../../../data/raw/${dataset.name}
  lc_metric: Train/val_accuracy
  split: 0.8
  dataset_meta_features:
    _target_: mf_gravitas.data.DatasetMetaFeatures
    path: ${dataset.preprocessed_path}/meta_features.csv
    index_col: 0
    transforms:
      _target_: mf_gravitas.data.preprocessings.transformpipeline.TransformPipeline
      modulelist:
      - _target_: mf_gravitas.data.preprocessings.nan_transforms.Zero_fill
      - _target_: mf_gravitas.data.preprocessings.table_transforms.ToTensor
  algo_meta_features:
    _target_: mf_gravitas.data.AlgorithmMetaFeatures
    path: ${dataset.preprocessed_path}/config_subset.csv
    index_col: 0
    transforms:
      _target_: mf_gravitas.data.preprocessings.transformpipeline.TransformPipeline
      modulelist:
      - _target_: mf_gravitas.data.preprocessings.nan_transforms.Zero_fill
      - _target_: mf_gravitas.data.preprocessings.table_transforms.Drop
        columns:
        - imputation_strategy
        - learning_rate_scheduler
        - loss
        - network
        - normalization_strategy
        - optimizer
        - activation
        - mlp_shape
      - _target_: mf_gravitas.data.preprocessings.table_transforms.Replace
        columns:
        - num_layers
        replacedict:
          'True': 1
      - _target_: mf_gravitas.data.preprocessings.table_transforms.Convert
        columns:
        - num_layers
        dtype: numeric
      - _target_: mf_gravitas.data.preprocessings.table_transforms.ToTensor
  learning_curves:
    _target_: mf_gravitas.data.Dataset_LC
    path: ${dataset.preprocessed_path}/logs_subset.h5
    transforms:
      _target_: mf_gravitas.data.preprocessings.transformpipeline.TransformPipeline
      modulelist:
      - _target_: mf_gravitas.data.preprocessings.nan_transforms.Column_Mean
      - _target_: mf_gravitas.data.preprocessings.lc_slice.LC_TimeSlice
        slice: 51
      - _target_: mf_gravitas.data.preprocessings.table_transforms.ToTensor
    metric: ${dataset.lc_metric}
model:
  model:
    _target_: mf_gravitas.models.autoencoder.ParticleGravityAutoencoder
    input_dim: 27
    hidden_dims:
    - 8
    - 4
    embedding_dim: 2
    weights:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    repellent_share: 0.5
    n_algos: 35
    device: cpu
evaluation:
  steps: 10
  evaluator:
    _target_: mf_gravitas.evaluation.optimal_rankings.ZeroShotOptimalDistance
    ranking_loss:
      _target_: sklearn.metrics.ndcg_score
    batch: 20
    scaler:
      _target_: sklearn.preprocessing.MinMaxScaler
training:
  schedule:
    _target_: mf_gravitas.trainer.schedules.train_schedule
    epochs:
    - 100
    - 100
    - 100
    lr: ${lr}
seed: 0
output_dir: ./tmp
num_competitors: 2
num_workers: 2
train_batch_size: 4
test_batch_size: 20
lr: 0.002
shuffle: true
wandb:
  id: null
  entity: tnt
  project: gravitas
  mode: offline
  job_type: train
  tags: []
  notes: This is a test for sequential pocedure
  group: sequential_test
  sync_tensorboard: false
  save_code: false
  resume: allow
