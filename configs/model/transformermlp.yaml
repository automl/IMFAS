_target_: imfas.models.transformerMLP.IMFASTransformerMLP

# fixme: dataset_metaf_encoder.hidden_dims[-1] should be a variable that can be utilized in decoder.hidden_dims[0]

dmetaf_dim: 100
#
#joint_dim: ${add:${dynamically_computed.n_data_meta_features}, ${model.dmetaf_dim}}

dataset_metaf_encoder:
  _target_: imfas.utils.mlp.MLP
  hidden_dims:
    - ${dynamically_computed.n_data_meta_features}
    - 100  # arbitrary value

positional_encoder:
  _target_: imfas.utils.positionalencoder.PositionalEncoder
  d_model: 51 # n_fidelities
  max_len: 171
  dropout: 0.1

transformer_lc:
  _target_: torch.nn.TransformerEncoder
  num_layers: 2 # how many transformer layers to stack
  encoder_layer:
    _target_: torch.nn.TransformerEncoderLayer
    d_model: 1  # batch trick: look at every curve one at a time to allow appropriate masking
    nhead: 1 # attention heads  d_model / nhead = 1 must be devisible
    dim_feedforward: 100
    dropout: 0.1
    activation: relu

    batch_first: True
    norm_first: False
    device: ${device}

  norm:
    _target_: torch.nn.LayerNorm
    normalized_shape: ${model.transformer_lc.encoder_layer.d_model}

decoder:
  _target_: imfas.utils.mlp.MLP
  hidden_dims:
    - ${add:100, 2550} # metaf encoding dim + n_fidelities * n_algos
    #    - ${model.joint_dim} # n_d_metaf_encoding_dim + transformer output dim
    - ${dynamically_computed.n_algos}

device: ${device}