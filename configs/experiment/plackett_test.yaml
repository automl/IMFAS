# @package _global_

# MLP(D) ---> PlackettLuceLoss
defaults:
  - override /dataset: lcbench
  - override /dataset/dataset_meta: lcbench_minimal
  - override /dataset/algo_meta: lcbench_minimal
  - override /trainer: basetrainer

dataset:
  train_dataset_class:
    _target_: imfas.data.Dataset_Join_Dmajor
    masking_fn:
      _target_: imfas.utils.masking.mask_lcs_randomly
      _partial_: True

  test_dataset_class:
    _target_: imfas.data.Dataset_Join_Dmajor
    # TODO @TIM alex proposed to hold it fix for test, but do the imfas procedure

  train_dataloader_class:
    batch_size: 10
    shuffle: True

  test_dataloader_class:
    batch_size: 10
    shuffle: False

model:
  _target_: imfas.models.plackett_test.PlackettTest
  encoder:
    # linear model:
    _target_: imfas.utils.mlp.MLP
    hidden_dims:
      - ${dynamically_computed.n_data_meta_features}
      - 100
      - ${dynamically_computed.n_algos}
    activation: 'relu'

trainer:
  trainerobj:
    _target_: imfas.trainer.base_trainer.BaseTrainer # todo switch out for Slice evaluator!

    optimizer:
      _target_: torch.optim.Adam
      lr: 0.001
      _partial_: True

  run_call:
    epochs: 1000
    train_loss_fn:
      _target_: imfas.losses.plackett_luce.PlackettLuceLoss
      k: 10
    #      _target_: imfas.losses.spearman.SpearmanLoss

    valid_loss_fns:
      top1_regret:
        _target_: imfas.evaluation.topk_regret.TopkMaxRegret
        k: 1
      top3_regret:
        _target_: imfas.evaluation.topk_regret.TopkMaxRegret
        k: 3
      plackett_luce3:
        _target_: imfas.losses.plackett_luce.PlackettLuceLoss
        k: 3
      plackett_luce10:
        _target_: imfas.losses.plackett_luce.PlackettLuceLoss
        k: 10
      spearman:
        _target_: imfas.losses.spearman.SpearmanLoss
      ndcg3:
        _target_: sklearn.metrics.ndcg_score
        _partial_: True
        k: 3
      ndcg1:
        _target_: sklearn.metrics.ndcg_score
        _partial_: True
        k: 1





wandb:
  notes: 'plackett test'
