# @package _global_

# MLP(D) ---> PlackettLuceLoss
defaults:
  - override /dataset: lcbench
  - override /dataset/dataset_meta: lcbench_minimal
  - override /dataset/algo_meta: lcbench_minimal
  - override /trainer: basetrainer

dataset:
  train_dataset_class:
    _target_: imfas.data.Dataset_Join_Dmajor
    masking_fn:
      _target_: imfas.utils.masking.mask_lcs_randomly
      _partial_: True

  test_dataset_class:
    _target_: imfas.data.Dataset_Join_Dmajor
    # TODO @TIM alex proposed to hold it fix for test, but do the imfas procedure

  train_dataloader_class:
    batch_size: 10

  test_dataloader_class:
    batch_size: 10

model:
  _target_: imfas.models.plackett_test.PlackettTest
  encoder:
    # linear model:
    _target_: imfas.utils.mlp.MLP
    hidden_dims:
      - ${dynamically_computed.n_data_meta_features}
      - ${dynamically_computed.n_algos}
    activation: 'identity'

trainer:
  trainerobj:
    _target_: imfas.trainer.base_trainer.BaseTrainer # todo switch out for Slice evaluator!

    optimizer:
      _target_: torch.optim.Adam
      lr: 0.0001
      _partial_: True

  run_call:
    epochs: 1000
    train_loss_fn:
      _target_: imfas.losses.plackett_luce.PlackettLuceLoss
      k: 3

    valid_loss_fns:
      topk1_regret:
        _target_: imfas.evaluation.topk_regret.TopkMaxRegret
        k: 1
      topk3_regret:
        _target_: imfas.evaluation.topk_regret.TopkMaxRegret
        k: 3
      spearman:
        _target_: imfas.losses.spearman.SpearmanLoss
      plackett_luce:
        _target_: imfas.losses.plackett_luce.PlackettLuceLoss
        k: 3




wandb:
  notes: 'plackett test'
